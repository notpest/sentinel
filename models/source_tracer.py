import joblib
import numpy as np
from sentence_transformers import SentenceTransformer

# --- Load Models at Startup ---
# This code runs once when the module is imported.

print("Initializing Source Tracer...")

# Define paths to the saved model artifacts
CLASSIFIER_PATH = 'assets/source_classifier.joblib'
ENCODER_PATH = 'assets/source_label_encoder.joblib'

try:
    # Load the trained classifier and label encoder
    classifier = joblib.load(CLASSIFIER_PATH)
    label_encoder = joblib.load(ENCODER_PATH)
    
    # Load the sentence transformer model from the library's cache
    embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
    
    print("âœ… Source Tracer initialized successfully.")
    
except FileNotFoundError:
    print("ðŸ”´ ERROR: Model files not found. Make sure 'source_classifier.joblib' and 'source_label_encoder.joblib' are in the 'assets' directory.")
    classifier = None
    label_encoder = None
    embedding_model = None


def trace_source(text_content: str) -> float:
    """
    Analyzes text to trace its origin to a known LLM and returns a confidence score.

    Args:
        text_content (str): The text to analyze.

    Returns:
        float: A confidence score (0.0 to 1.0) indicating the likelihood that the
               text was generated by a known AI model.
    """
    print("-> Running source tracing...")

    if not all([classifier, label_encoder, embedding_model]):
        print("   Source Tracer is not initialized. Returning score 0.0.")
        return 0.0

    # 1. Generate the embedding for the input text
    input_embedding = embedding_model.encode([text_content])

    # 2. Predict the probability for each class
    # predict_proba gives a confidence score for each possible source LLM
    probabilities = classifier.predict_proba(input_embedding)
    
    # 3. Get the highest probability and the predicted class index
    confidence_score = np.max(probabilities)
    predicted_index = np.argmax(probabilities)

    # 4. Decode the predicted class name for logging/debugging
    predicted_model_name = label_encoder.inverse_transform([predicted_index])[0]
    
    print(f"   Predicted Source: '{predicted_model_name}' with confidence: {confidence_score:.2f}")

    # 5. Return both the model name and the score in a dictionary
    return {
        'model_name': predicted_model_name,
        'score': float(confidence_score)
    }